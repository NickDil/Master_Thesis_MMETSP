import pandas as pd
import numpy as np
import argparse
import glob
import json
import subprocess
import os
from time import gmtime, strftime
from bokeh.palettes import all_palettes #@Unresolvedreference

#bookeh
from bokeh.core.properties import value
from bokeh.models import Range1d, LinearAxis, HoverTool, ColumnDataSource, OpenURL, TapTool, Legend
from bokeh.transform import dodge
from bokeh.plotting import figure, output_file, show


def get_param():
    '''
    Function that parses command line input of parameters needed to execute the plot_QC.py script.

    :return:
    Dictionary with input parameters
    '''

    parser = argparse.ArgumentParser(description='Generate "Quality Control Visualization" for one set of experiments. '
                                                 'All paths should be absolute and end with "/"')

    #New group for required named arguments
    requiredNamed = parser.add_argument_group('required named arguments')

    # title for the QC analysis
    parser.add_argument('-name', '-n', type=str, default='QC_analysis', help="Name your analysis,"
                                                                             " defaults to 'QC_analysis'")
    # Use previous datafile if present?
    parser.add_argument('-input_existing', '-i', type=str, help="Use previously generated .csv files based on analysis name "
                                                                "instead of re-doing analysis via R. Argument should "
                                                                "specify a directory that has 2 csv files generated by"
                                                                " running this script with queries")
    # location of data/executables
    parser.add_argument('data_location', type=str, help="data_location (absolute path) e.g. '/path/to/experiment_data'")
    parser.add_argument('project_script_location', type=str, help="project_script_location (Absolute path) "
                                                                         "e.g. '/path/to/Project_trapid/Scripts/'")

    # optional output directory
    parser.add_argument('-output', '-o', type=str, help='Defaults to working directory. Output directory for the results, figures if using '
                                                        'the -input_existing argument, figures and csv files otherwise. '
                                                        'When -o not given but using -input_existing argument output will be printed to that directory.')
    # Taxonomic scope/resolution of analysis
    parser.add_argument('-tax_res', '-t', type=str, default= 'genus', help="Taxonomic resolution of visualization "
                                                         "(supported are 'species', 'genus' and 'phylum'), defaults to 'genus'")
    # Arguments for selection of experiments
    parser.add_argument('user_id', type=str, help='user id to select experiments')

    #parser.add_argument('-desc_query', '-dq', nargs='+', help='query de descritption of the experiments')
    parser.add_argument('-desc_query', '-dq', type=str, help='query the descritption of the experiments')
    parser.add_argument('-tax_query', '-tq', type=str, help='query based on tax id of the experiments')
    parser.add_argument('-refDB_query', '-dbq', type=str, help='query the used reference DB of the experiments')
    parser.add_argument('-phylum', '-pq', type=str, help='query based on the phylum of the experiments')
    parser.add_argument('-genus', '-gq', type=str, help='query based on the genus of the experiments')
    parser.add_argument('-species', '-sq', type=str, help='query based on the species of the experiments')
    parser.add_argument('-min_trs', '-m', default=1, type=int, help='minimum number of transcripts to have to be inculded in selection. Default 1')

    # # experiment parameters
    # parser.add_argument('-reference_db_server', '-s', type=str, help='Server name where reference DB is located')
    # parser.add_argument('-reference_db_pswd', '-p', type=str, help='Password to connect to database')
    # parser.add_argument('-reference_db_name', '-n', type=str, help='Name of reference DB')
    # parser.add_argument('-reference_db_user', '-u', type=str, help='username to connect to reference DB')
    # parser.add_argument('-reference_db_port', '-c', type=int, help='Portname to reference DB server')

    args = parser.parse_args()
    out_dict = vars(args)
    return out_dict

def get_R_data(args):

    data_dir_ex = args.pop('input_existing', None)

    if not data_dir_ex:
        print("[START]: R analysis of experiments:", strftime("%Y-%m-%d %H:%M:%S", gmtime()), "\n")

        # Define command and arguments
        command = 'Rscript'
        path2script = args['project_script_location'] + 'Compare/R/R_scripts/collect_data.R'

        # Set output dir to working dir if not specified
        if not args["output"]:
            args["output"] = "./"

        # Variable number of args in a list, make all strings
        L = list(map(str, list(args.values())))

        # Build subprocess command
        cmd = [command, path2script] + L

        # check_output will run the command and store to result
        try:
            x = subprocess.check_output(cmd, universal_newlines=True)
        except subprocess.CalledProcessError as xc:
            print("error code", xc.returncode, xc.output)

        # x = subprocess.check_output(cmd, universal_newlines=True)
        print("[STOP]: R analysis of experiments:", strftime("%Y-%m-%d %H:%M:%S", gmtime()), "\n")

        results_dir = args["output"] + "{name}_results/".format(name=args["name"])

        print("R output:\n", x)
        print("Reading generated files:\n")
        print("{name}_results/Data/{name}_main.csv\n".format(name=args["name"]))
        data_main = pd.read_table(args["output"] + "{name}_results/Data/{name}_main.csv".format(name=args["name"]), sep=",", encoding='latin-1')
        print("{name}_results/Data/{name}_txcmp.csv\n".format(name=args["name"]))
        data_txcmp = pd.read_table(args["output"] + "{name}_results/Data/{name}_txcmp.csv".format(name=args["name"]), sep=",", encoding='latin-1')

    else:
        print("[USING PREVIOUSELY GENERATED DATA]\n")
        files = glob.glob(data_dir_ex + '*')
        file_main = [x for x in files if x.endswith('_main.csv')]
        file_txcmp = [x for x in files if x.endswith('_txcmp.csv')]

        # raise IOError if no or multiple .csv files present in dir
        if len(file_main) != 1 : raise IOError(
            'no or multiple _main.csv file in {d}; These files are found {file}'.format(d=data_dir_ex, file=file_main))
        if len(file_txcmp) != 1 : raise IOError(
            'no or multiple _main.csv file in {d}; These files are found {file}'.format(d=data_dir_ex, file=file_txcmp))

        print("[START] Reading files:\n")
        print(file_main[0], "\n")
        data_main = pd.read_table(file_main[0], sep=",", encoding='latin-1')
        print(file_txcmp[0], "\n")
        data_txcmp = pd.read_table(file_txcmp[0], sep=",", encoding='latin-1')
        print("[STOP] Reading files\n")

        # Set output dir to source location if not specified otherwise
        if not args["output"]:
            results_dir = data_dir_ex.rstrip("Dat/") + "/"
        else:
            results_dir = args["output"] + "{name}_results/".format(name=args["name"])

    return data_main, data_txcmp, results_dir

def plot_trs_count(data_main, out_dir):
    output_file(out_dir+"trs_count_bars.html")

    palette = ["#718dbf", "#e84d60", 'violet']

    source = ColumnDataSource(data_main)

    hover = HoverTool(tooltips=[
        ("title", "@title"),
        ("organism", "@species_MMETSP"),
        ("phylum", "@phylum_MMETSP"),
        ("# trs", "@experiment_id"),
        ("core_gf_score", "@transcripts_count_total"),
    ], mode='vline')

    tools_to_show = [hover, "box_zoom,pan,save,reset,wheel_zoom,tap"]
    p = figure(x_range=list(data_main['title']),
               y_range=(0, max(data_main['transcripts_count_total']) + 0.2*max(data_main['transcripts_count_total'])),
               plot_width=1600, plot_height=800, tools=tools_to_show, title="Transcript counts per sample")

    p.vbar(x=dodge('title', -0.15, range=p.x_range), top='transcripts_count_total', width=0.2, source=source,
           color=palette[0], legend=value("transcripts_count_total"))

    p.vbar(x=dodge('title', 0.15, range=p.x_range), top='transcripts_count_annot', width=0.2, source=source,
           color=palette[1], legend=value("transcripts_count_annot"))



    #Add Taptool
    url = "http://bioinformatics.psb.ugent.be/testix/trapid_frbuc/tools/statistics/@experiment_id"
    taptool = p.select(type=TapTool)
    taptool.callback = OpenURL(url=url)

    p.toolbar_location = 'above'
    p.x_range.range_padding = 0.1
    p.xaxis.major_label_orientation = 3.1514 / 4
    p.xgrid.grid_line_color = None
    p.legend.location = "top_right"
    p.legend.orientation = "horizontal"
    p.legend.click_policy = "hide"

    show(p)

def plot_completeness_score(data_main, out_dir):
    output_file(out_dir + data_main["used_method"][0] + "completeness_score.html")

    x = data_main.sort_values(by=['completeness_score'])
    x["quantile"] = np.array(range(x.shape[0]))/x.shape[0]*100
    source = ColumnDataSource(x)

    hover = HoverTool(tooltips=[
        ("title", "@title"),
        ("organism", "@species_MMETSP"),
        ("phylum", "@phylum_MMETSP"),
        ("number of transcipts", "@transcripts_count_total"),
        ("number of transcipts with annotation ", "@transcripts_count_annot"),
        ("core_gf_score", "@completeness_score"),
        ("index", "$index"),
        ("quantile", "@quantile%")
    ], mode='vline')

    tools_to_show = [hover, "box_zoom,pan,save,reset,wheel_zoom,tap,crosshair"]
    p = figure(x_range=list(x['title']), y_axis_label='core NOG completeness score',
               y_range=(0, max(x['completeness_score']) + 0.2 * max(x['completeness_score'])),
               plot_width=1600, plot_height=800, tools=tools_to_show, title="completeness_score per sample")
    p.vbar(x='title', top='completeness_score', width=1, source=source,
           legend=value("completeness_score"))

    # If you want to add completeness score to plot
    p.extra_y_ranges = {"counts": Range1d(start=0, end=max(x['transcripts_count_total']) + 0.2 * max(x['transcripts_count_total']))}
    p.add_layout(LinearAxis(y_range_name="counts", axis_label='number of transcripts'), 'right')

    p.vbar(x='title', top='transcripts_count_total', width=0, source=source,
           color='red', y_range_name='counts', legend=value("transcripts_count_total"))

    # Add Taptool
    url = "http://bioinformatics.psb.ugent.be/testix/trapid_frbuc/tools/statistics/@experiment_id"
    taptool = p.select(type=TapTool)
    taptool.callback = OpenURL(url=url)

    p.toolbar_location = 'above'
    p.x_range.range_padding = 0.1
    p.xaxis.major_label_orientation = 3.1514 / 4
    p.xgrid.grid_line_color = None
    p.legend.location = "top_right"
    p.legend.orientation = "horizontal"
    p.legend.click_policy = "hide"

    show(p)

def plot_completeness_score_bins(data_main, out_dir):
    output_file(out_dir + "taxonomic_composition.html")

    indices = np.unique(data_cutoff['title'], return_index=True)[1]
    titles = [data_cutoff['title'].iloc[index] for index in sorted(indices)]



    taxblocks = list(np.unique(data_cutoff['tax_annot']))

    colids = []
    for i in range(len(taxblocks)-1):
        colids.append(round(i*256/len(taxblocks)))


    colors = list(np.array(all_palettes['Viridis'][256])[colids])


    new_dict = {"title": titles}
    for tax in taxblocks:
        dd = {el: 0 for el in titles}
        tax_df = data_cutoff[data_cutoff["tax_annot"] == tax]
        for sample in tax_df['title']:
            dd[sample] = float(tax_df['transcripts_percent'][data_cutoff["title"] == sample])*100

        new_dict[tax] = list(dd.values())

    #add other category to complete bars to 100%
    forother = list(100 - pd.DataFrame(new_dict).sum(axis=1))
    new_dict["Other"] = forother
    taxblocks.append("Other")

    #rearange and color
    taxblocks.remove('unclassified')
    taxblocks.append('unclassified')
    colors.append('darkslategrey')
    colors.append('black')

    source = ColumnDataSource(new_dict)
    tools_to_show = ["box_zoom,pan,save,reset,wheel_zoom,tap"]

    p = figure(y_range=titles, title="Taxonomic binning (kaiju) per sample",
               toolbar_location=None, tools=tools_to_show, plot_width=1800, plot_height=1000)

    renderers = p.hbar_stack(taxblocks, y='title', height=0.9,  source=source, color=colors, name=taxblocks)
    # legend=[value(x) for x in taxblocks]

    items = []
    for r in renderers:
        x = r.name
        hover = HoverTool(tooltips=[
            ("title", "@title"),
            ("%s" % x, "@%s" % x)
        ], renderers=[r], toggleable=False)
        p.add_tools(hover)
        items.append((r.name, [r]))

    #Add Taptool
    url = "http://bioinformatics.psb.ugent.be/testix/trapid_frbuc/tools/statistics/@experiment_id"
    taptool = p.select(type=TapTool)
    taptool.callback = OpenURL(url=url)

    legend = Legend(items=items, location=(0, 0))

    p.toolbar_location = 'above'
    p.x_range.range_padding = 0.1
    p.xaxis.major_label_orientation = 3.1514 / 4
    p.xgrid.grid_line_color = None
    p.add_layout(legend, 'right')
    p.legend.click_policy = "hide"

    show(p)

def get_colors(n):
    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct
    RGB color; the keyword argument name must be a standard mpl colormap name.'''

def plot_taxcomp(data_txcmp, cutoff, out_dir):
    output_file(out_dir + "taxonomic_composition.html")

    data_cutoff = data_txcmp[data_txcmp["transcripts_percent"] > cutoff]

    indices = np.unique(data_cutoff['title'], return_index=True)[1]
    titles = [data_cutoff['title'].iloc[index] for index in sorted(indices)]



    taxblocks = list(np.unique(data_cutoff['tax_annot']))

    colids = []
    for i in range(len(taxblocks)-1):
        colids.append(round(i*256/len(taxblocks)))


    colors = list(np.array(all_palettes['Viridis'][256])[colids])


    new_dict = {"title": titles}
    for tax in taxblocks:
        dd = {el: 0 for el in titles}
        tax_df = data_cutoff[data_cutoff["tax_annot"] == tax]
        for sample in tax_df['title']:
            dd[sample] = float(tax_df['transcripts_percent'][data_cutoff["title"] == sample])*100

        new_dict[tax] = list(dd.values())

    #add other category to complete bars to 100%
    forother = list(100 - pd.DataFrame(new_dict).sum(axis=1))
    new_dict["Other"] = forother
    taxblocks.append("Other")

    #rearange and color
    taxblocks.remove('unclassified')
    taxblocks.append('unclassified')
    colors.append('darkslategrey')
    colors.append('black')

    source = ColumnDataSource(new_dict)
    tools_to_show = ["box_zoom,pan,save,reset,wheel_zoom,tap"]

    p = figure(y_range=titles, title="Taxonomic binning (kaiju) per sample",
               toolbar_location=None, tools=tools_to_show, plot_width=1800, plot_height=1000)

    renderers = p.hbar_stack(taxblocks, y='title', height=0.9,  source=source, color=colors, name=taxblocks)
    # legend=[value(x) for x in taxblocks]

    items = []
    for r in renderers:
        x = r.name
        hover = HoverTool(tooltips=[
            ("title", "@title"),
            ("%s" % x, "@%s" % x)
        ], renderers=[r], toggleable=False)
        p.add_tools(hover)
        items.append((r.name, [r]))

    #Add Taptool
    url = "http://bioinformatics.psb.ugent.be/testix/trapid_frbuc/tools/statistics/@experiment_id"
    taptool = p.select(type=TapTool)
    taptool.callback = OpenURL(url=url)

    legend = Legend(items=items, location=(0, 0))

    p.toolbar_location = 'above'
    p.x_range.range_padding = 0.1
    p.xaxis.major_label_orientation = 3.1514 / 4
    p.xgrid.grid_line_color = None
    p.add_layout(legend, 'right')
    p.legend.click_policy = "hide"

    show(p)

def main():

    args = get_param()

    #Run R analysis or retrieve previous analysis (~parameters)
    data_main, data_txcmp, results_dir = get_R_data(args)

    # plot QC figures with Bokeh), DONT USE IF COMPLETENESS SCORE AVAILABLE
    # plot_trs_count(data_main, results_dir)

    # plot completeness-scores
    print(results_dir)
    plot_completeness_score(data_main, results_dir)

    #plot taxbin figure
    # plot_taxcomp(data_txcmp, 0.1, results_dir)


if __name__ == '__main__':
    main()
