import select_experiments
import create_NOG_matrix
import FLAME_clustering
import Heatmap_rect_bokeh_V0_12_15

import subprocess
import argparse
import json
from time import gmtime, strftime


''' This is a wrapper with annotations to each step to run the SUPERVISED analysis of th MMETSP dataset'''

def get_param():

    '''
    Function that parses command line input of parameters needed to execute the plot_QC.py script.

    :return:
    Dictionary with input parameters
    '''

    parser = argparse.ArgumentParser(description='Generate "Quality Control Visualization" for one set of experiments. '
                                                 'All paths should be absolute and end with "/"')

    #New group for required named arguments
    requiredNamed = parser.add_argument_group('required named arguments')

    # title for the QC analysis
    parser.add_argument('-name', '-n', type=str, default='MY_SELECTED_SAMPLES', help="Name your selection,"
                                                                             " defaults to 'MY_SELECTED_SAMPLES'")
    # Use previous datafile if present?
    parser.add_argument('-input_existing', '-i', type=str, help="Use previously generated .csv files based on analysis name "
                                                                "instead of re-doing analysis via R. Argument should "
                                                                "specify a directory that has 2 csv files generated by"
                                                                " running this script with queries")
    # location of data/executables
    parser.add_argument('data_location', type=str, help="data_location (absolute path) e.g. '/path/to/experiment_data'")
    parser.add_argument('project_script_location', type=str, help="project_script_location (Absolute path) "
                                                                         "e.g. '/path/to/Project_trapid/Scripts/'")

    # optional output directory
    parser.add_argument('-output', '-o', type=str, help='Defaults to working directory. Output directory for the results, figures if using '
                                                        'the -input_existing argument, figures and csv files otherwise. '
                                                        'When -o not given but using -input_existing argument output will be printed to that directory.')
    # Taxonomic scope/resolution of analysis
    parser.add_argument('-tax_res', '-t', type=str, default= 'genus', help="Taxonomic resolution of visualization "
                                                         "(supported are 'species', 'genus' and 'phylum'), defaults to 'genus'")
    # Arguments for selection of experiments
    parser.add_argument('user_id', type=str, help='user id to select experiments')

    #Minimum completeness score of experiments
    parser.add_argument('-min_completeness', '-mc', default=0, type=str, help='minimun completeness score for experiment/sample to be included. Default 0; include all')

    #parser.add_argument('-desc_query', '-dq', nargs='+', help='query de descritption of the experiments')
    parser.add_argument('-desc_query', '-dq', type=str, help='query the descritption of the experiments')
    parser.add_argument('-tax_query', '-tq', type=str, help='query based on tax id of the experiments')
    parser.add_argument('-refDB_query', '-dbq', type=str, help='query the used reference DB of the experiments')
    parser.add_argument('-phylum', '-pq', type=str, help='query based on the phylum of the experiments')
    parser.add_argument('-genus', '-gq', type=str, help='query based on the genus of the experiments')
    parser.add_argument('-species', '-sq', type=str, help='query based on the species of the experiments')
    parser.add_argument('-min_trs', '-min', default=1, type=int, help='minimum number of transcripts to have to be inculded in selection. Default 1')

    # Filters for metadata quality assesment
    parser.add_argument('-metadata_type', '-m', type=str, help=' Filter samples based on MMETSP metadata attribute (check mmetsp_metadata DB')
    parser.add_argument('-metadata_cutoff', '-c', type=str, default=0, help='Cutoff value to include metadata levels only if <metadata_cutoff> amount of samples or annotated (only use for categorical data or if checked)')

    #############################################
    # create_NOG_matrix
    parser.add_argument('infile', type=str, help="input like _main.csv")
    parser.add_argument('-GO', type=str, default="None", help='GO term to select NOGs')
    parser.add_argument('-min_occurence', '-mo', default=1, type=str, help='minimun occurence in experiments for NOG to be included. Default 1; include all.')
    parser.add_argument('-outdir', '-o', type=str, default="./", help="output directory")
    parser.add_argument('-counts',  action='store_true', help="switch on to use the transcript counts instead of just using GF presence (binary)")
    parser.add_argument('-normalize', "-n", action='store_true', help="switch on to normalize GF feature martix")

    #############################################
    # FLAME clustering
    parser.add_argument('input_table', type=str, help="Input file (space separated) of sample X feature matrix to be clustered, "
                                             "first line with dimensions should be present")
    parser.add_argument('flame_path', type=str, default=1, help="Path to flame algorithm")
    parser.add_argument('-axis', type=str, default='0', help="Which axis to use as instances, the other axis is used as features. Row:0 (default), col:1. To do both you can pass 01 or 10")
    parser.add_argument('-d', type=str, default="1", help="Distance funcion, check readme in 'flame-clustering/' dir. Defaults to euclidian (d=1)")
    parser.add_argument('-knn', type=str, default="15", help='K nearest neighbours, parameter for FLAME. Default knn=15')
    parser.add_argument('-write',  action='store_true', help="Write clustering results to a file (compatible with dreec enricher")
    parser.add_argument('-outdir', '-o', type=str, help="Specify output directory")
    parser.add_argument('-keep', action='store_true', help="toggle to keep parsed NOG matrix")

def read_init_file():
    parser = argparse.ArgumentParser(description='SUPERVISED analysis of MMETSP samples')
    parser.add_argument('config_file', help="Configuration file specifying all your parameters", type=argparse.FileType('r', encoding='UTF-8'))
    args = parser.parse_args()
    with args.config_file as json_data_file:
        config_data = json.load(json_data_file)
    args.config_file.close()
    return config_data

def main(parameters):

    ########### 1. Select experiments you want to include in your analysis ###########
    print("\n[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[*** [1/5] SELECTING EXPERIMENTS***]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\n")
    # define parameters1 for select_experiment.py
    parameters1 = {'name': 'TEST', 'data_location': '/my/data/loc/', 'project_script_location': '../../', 'outdir': './', 'tax_res': 'genus', 'user_id': None, 'min_completeness': 0, 'desc_query': None, 'tax_query': None, 'refDB_query': None, 'phylum': None, 'genus': None, 'species': None, 'min_trs': 1, 'metadata_type': None, 'metadata_cutoff': 0}
    for param in parameters:
        if param in parameters1:
            parameters1[param] = parameters[param]
    select_experiments.main(parameters1)
    print(parameters1)


    ########### 2. Create NOG-feature matrix for these experiments ###########
    print("\n[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[*** [2/5] CREATING NOG MATRIX***]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\n")

    #specify data_main in parameters
    infile_location = "{outdir}{name}/Data/{name}_main.csv".format(outdir=parameters1['outdir'], name=parameters1["name"])
    parameters["infile"] = infile_location

    parameters2 = {'infile': 'path/to/data/', 'project_script_location': '../../../', 'GO': 'None', 'min_occurence': '0', 'outdir': './', 'counts': False, 'normalize': False}
    for param in parameters:
        if param in parameters2:
            parameters2[param] = parameters[param]
    # change output dir
    parameters2['outdir'] = parameters1["outdir"]+parameters["name"]+"/"

    create_NOG_matrix.main(parameters2)
    print(parameters2)

    ########### 3. Cluster this matrix with the FLAME algorithm ###########
    print("\n[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[*** [3/5] FLAME CLUSTERING***]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\n")

    #specify NOG_matrix location in parameters
    if parameters2["counts"] == 'False' or not parameters2["counts"]:
        count_str=""
    else:
        count_str = "_counts"

    # Specify where NOG matrix is located
    NOG_MATRIX = "NOG_MATRIX_minocc{mo}_{go}{cs}".format(mo=parameters2["min_occurence"],go= "_".join(parameters2["GO"].split(':')), cs=count_str)
    NOG_MATRIX_location = "{outdir}{name}/{NOG_MATRIX}/{NOG_MATRIX}.txt".format(outdir=parameters1['outdir'], name=parameters1["name"], NOG_MATRIX=NOG_MATRIX)
    NOG_MATRIX_directory = parameters2["outdir"]+NOG_MATRIX+"/"
    parameters["input_table"] = NOG_MATRIX_location

    cluster_list_samples = None
    cluster_list_NOG = None

    # Check if cluster in 2 ways
    if parameters.get('d') and parameters.get('knn'):
        parameters3_0 = {'input_table': 'NOG_MATRIX_minocc4_None_counts.txt',
                       'flame_path': '../../../../flame-clustering/sample', 'd': '1', 'knn': '4',
                       'write': True, 'keep': False}
        for param in parameters:
            if param in parameters3_0:
                parameters3_0[param] = parameters[param]
                if parameters[param].upper() == "TRUE":
                    parameters3_0[param] = True
                elif parameters[param].upper() == "FALSE":
                    parameters3_0[param] = False

                parameters3_0['outdir'] = NOG_MATRIX_directory

        print("\n[INFO] FLAME-clustering along first axis with parameters: d=", parameters3_0["d"]," knn=", parameters3_0["knn"])
        parameters3_0['axis'] = "0"

        FLAME_clustering.main(parameters3_0)
        cluster_list_samples = "{dir}FLAME_output_d{d}_knn{knn}_axis0/FLAME_output_d{d}_knn{knn}_axis0.txt".format(dir=NOG_MATRIX_directory, d=parameters['d'], knn=parameters['knn'])


    if parameters.get('d1') and parameters.get('knn1'):
        parameters3_1 = {'input_table': 'NOG_MATRIX_minocc4_None_counts.txt',
                       'flame_path': '../../../../flame-clustering/sample', 'd1': '1', 'knn1': '4',
                       'write': True, 'keep': False}
        for param in parameters:
            if param in parameters3_1:
                parameters3_1[param] = parameters[param]
                if parameters[param].upper() == "TRUE":
                    parameters3_1[param] = True
                elif parameters[param].upper() == "FALSE":
                    parameters3_1[param] = False

                    parameters3_1['outdir'] = NOG_MATRIX_directory

        parameters3_1['axis'] = "1"
        parameters3_1['d'] = parameters3_1['d1']
        parameters3_1['knn'] = parameters3_1['knn1']
        print("\n[INFO] FLAME-clustering along second axis with parameters: d=", parameters3_1["d"]," knn=", parameters3_1["knn"])

        FLAME_clustering.main(parameters3_1)

        cluster_list_NOG = "{dir}FLAME_output_d{d}_knn{knn}_axis1/FLAME_output_d{d}_knn{knn}_axis1.txt".format(dir=NOG_MATRIX_directory, d=parameters['d1'], knn=parameters['knn1'])

    ########## 4. Do enrichment analysis ###########
    print("\n[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[*** [4/5] ENRICHMENT ANALYSIS***]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\n")
    print(strftime("%Y-%m-%d %H:%M:%S", gmtime()), "\t[START] Enrichment analysis")
    #defing ftr_file and cluster_list
    ftr_file = "{outdir}{name}/Data/metadata.txt".format(outdir=parameters1['outdir'], name=parameters1["name"])

    if cluster_list_samples:
        command = [parameters["enricher_location"], ftr_file, cluster_list_samples] + parameters["arguments_string"].split(" ")
        x = subprocess.check_output(command, universal_newlines=True)

        enricher_filepath0 = "{dir}/enricher_output_minocc{mo}_{go}{cs}_d{d}knn{knn}ax0.txt".format(dir="/".join(cluster_list_samples.split("/")[:-1]),
                                                                        mo=parameters2["min_occurence"],
                                                                        go="_".join(parameters2["GO"].split(':')),
                                                                        cs=count_str,
                                                                        d=parameters['d'],
                                                                        knn=parameters['knn'])
        f = open(enricher_filepath0, 'w+')
        f.write(x)
        f.close()
        print("[INFO] Output enrichment analysis written to:", enricher_filepath0)
        print(strftime("%Y-%m-%d %H:%M:%S", gmtime()), "\t[STOP] Enrichment analysis")



    ## NONSENSICAL !!!! UPDATE WHEN SOME KIN OF METADATA
    # if cluster_list_NOG:
    #     command = [parameters["enricher_location"], ftr_file, cluster_list_NOG] + parameters[
    #         "arguments_string"].split(" ")
    #     x = subprocess.check_output(command, universal_newlines=True)
    #
    #     enricher_filepath1 = "{dir}/enricher_output_minocc{mo}_{go}{cs}_d{d}knn{knn}ax1.txt".format(
    #         dir="/".join(cluster_list_NOG.split("/")[:-1]),
    #         mo=parameters2["min_occurence"],
    #         go="_".join(parameters2["GO"].split(':')),
    #         cs=count_str,
    #         d=parameters['d1'],
    #         knn=parameters['knn1'])
    #
    #     f = open(enricher_filepath1, 'w+')
    #     f.write(x)
    #     f.close()
    #     print("[INFO] Output enrichment analysis written to:", enricher_filepath1)
    #     print(strftime("%Y-%m-%d %H:%M:%S", gmtime()), "\t[STOP] Enrichment analysis")



    ########### 5. Create heatmap ###########
    print("\n[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[*** [5/5] DRAW HEATMAP***]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]]\n")
    print(strftime("%Y-%m-%d %H:%M:%S", gmtime()), "\t[START] Creating heatmap")

    parameters4 = {'input_table': None, 'outdir': None, 'row_order': cluster_list_samples, 'col_order': cluster_list_NOG,
     'data_main': infile_location, 'greyscale': False, 'show': False, 'DBCONFIG': parameters["project_script_location"]+"config_connect_trapid.json"}

    for param in parameters:
        if param in parameters4:
            parameters4[param] = parameters[param]
            if parameters[param].upper() == "TRUE":
                parameters4[param] = True
            elif parameters[param].upper() == "FALSE":
                parameters4[param] = False

    # Change output dir
    parameters4['outdir'] = NOG_MATRIX_directory
    print(parameters4)

    Heatmap_rect_bokeh_V0_12_15.main(parameters4)

    print("[INFO] Heatmap stored in {}".format(parameters4['outdir']))
    print(strftime("%Y-%m-%d %H:%M:%S", gmtime()), "\t[STOP] Creating heatmap")

if __name__ == '__main__':
    parameters = read_init_file()
    main(parameters)
